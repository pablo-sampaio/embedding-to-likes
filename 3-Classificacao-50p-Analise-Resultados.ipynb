{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise dos Resultados da Previsão de Engajamento - Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 3119,
     "status": "ok",
     "timestamp": 1678973020538,
     "user": {
      "displayName": "PABLO SAMPAIO",
      "userId": "06578877141428254753"
     },
     "user_tz": 180
    },
    "id": "OJV4GlB7-Jqx",
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#@title Importações de pacote\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from util import load_results, filter_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "BASE_PATH = 'dados/preprocessed/'\n",
    "TYPE_NAME = 'paraphrase-multilingual-MiniLM'\n",
    "SOCIAL_NETWORK = 'tiktok'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALTERE AQUI !!!\n",
    "RESULTS_FILE_PATH = \"resultados/resultados50p_2025-04-02-18h10m_lula(mxbai-embed-large-v1)_(tiktok).npy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xg4V0QFFLo7g"
   },
   "source": [
    "# 1 - Carregando Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando os dados dos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata, results = load_results(RESULTS_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '2025-04-02-18h10m',\n",
       " 'subdataset': 'lula',\n",
       " 'target': 'Curtidas-2Classes-50p',\n",
       " 'random_state': 1231,\n",
       " 'description': 'Treinamento com modelos com os \\ndados balanceados (50p), com o dataset lula, com todos os modelos \\ne com novos ENSEMBLE',\n",
       " 'basic_models': ['MLP Neural Network',\n",
       "  'Support Vector Machine',\n",
       "  'Random Forest',\n",
       "  'Logistic Regression',\n",
       "  'KNN']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_SocVpnTp-p"
   },
   "source": [
    "Carregando dados brutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 838,
     "status": "ok",
     "timestamp": 1678973021364,
     "user": {
      "displayName": "PABLO SAMPAIO",
      "userId": "06578877141428254753"
     },
     "user_tz": 180
    },
    "id": "pbGadD5L-aMf",
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "dfx_full = pd.read_excel(f\"{BASE_PATH}full-preproc2-inputs_{TYPE_NAME}_{SOCIAL_NETWORK}.xlsx\", index_col='ID')\n",
    "dfy_full = pd.read_excel(f\"{BASE_PATH}full-preproc2-outputs_{TYPE_NAME}_{SOCIAL_NETWORK}.xlsx\", index_col='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset LULA (indicador 1)\n"
     ]
    }
   ],
   "source": [
    "dfx, dfy = filter_dataset(dfx_full, dfy_full, subdataset=metadata['subdataset'], target_col=metadata['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Only Hashtags', 'Dias Decorridos', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6',\n",
       "       'x7', 'x8',\n",
       "       ...\n",
       "       'x375', 'x376', 'x377', 'x378', 'x379', 'x380', 'x381', 'x382', 'x383',\n",
       "       'x384'],\n",
       "      dtype='object', length=386)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MLP Neural Network',\n",
       " 'Support Vector Machine',\n",
       " 'Random Forest',\n",
       " 'Logistic Regression',\n",
       " 'KNN']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASIC_MODEL_NAMES = metadata['basic_models']\n",
    "BASIC_MODEL_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOTAL_SPLITS = results[BASIC_MODEL_NAMES[0]]['cv_model'].get_n_splits()\n",
    "TOTAL_SPLITS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Métricas Principais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos testados:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['MLP Neural Network', 'Support Vector Machine', 'Random Forest', 'Logistic Regression', 'KNN', 'FOLD_00-hard-vote', 'FOLD_00-soft-vote', 'FOLD_01-hard-vote', 'FOLD_01-soft-vote', 'FOLD_02-hard-vote', 'FOLD_02-soft-vote', 'FOLD_03-hard-vote', 'FOLD_03-soft-vote', 'FOLD_04-hard-vote', 'FOLD_04-soft-vote', 'FOLD_05-hard-vote', 'FOLD_05-soft-vote', 'FOLD_06-hard-vote', 'FOLD_06-soft-vote', 'FOLD_07-hard-vote', 'FOLD_07-soft-vote', 'FOLD_08-hard-vote', 'FOLD_08-soft-vote', 'FOLD_09-hard-vote', 'FOLD_09-soft-vote', 'Best-hard-vote', 'Best-soft-vote'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelos disponíveis (básicos e ensemble)\n",
    "print(\"Modelos testados:\")\n",
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "METRICS = ['f1_score_mean', 'f1_score_std', 'precision_mean', 'precision_std', 'recall_mean', 'recall_std', 'accuracy_mean', 'accuracy_std', 'auc_roc_mean', 'auc_roc_std', 'auc_pr_mean', 'auc_pr_std']\n",
    "#METRICS = ['F1_score_mean', 'F1_score_std', 'Precisão_mean', 'Precisão_std', 'Revocação_mean', 'Revocação_std', 'Acurácia_mean', 'Acurácia_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(results).T\n",
    "df_result = df_result[METRICS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_score_mean</th>\n",
       "      <th>f1_score_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>precision_std</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>accuracy_mean</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>auc_roc_mean</th>\n",
       "      <th>auc_roc_std</th>\n",
       "      <th>auc_pr_mean</th>\n",
       "      <th>auc_pr_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MLP Neural Network</th>\n",
       "      <td>0.666651</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005184</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.005184</td>\n",
       "      <td>0.497052</td>\n",
       "      <td>0.078692</td>\n",
       "      <td>0.533995</td>\n",
       "      <td>0.067457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.589446</td>\n",
       "      <td>0.067411</td>\n",
       "      <td>0.514962</td>\n",
       "      <td>0.041459</td>\n",
       "      <td>0.741075</td>\n",
       "      <td>0.22397</td>\n",
       "      <td>0.509783</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.526611</td>\n",
       "      <td>0.040915</td>\n",
       "      <td>0.535623</td>\n",
       "      <td>0.045732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <td>0.545904</td>\n",
       "      <td>0.069495</td>\n",
       "      <td>0.498868</td>\n",
       "      <td>0.015023</td>\n",
       "      <td>0.635484</td>\n",
       "      <td>0.199922</td>\n",
       "      <td>0.496748</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>0.488078</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>0.537086</td>\n",
       "      <td>0.049541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.524571</td>\n",
       "      <td>0.064123</td>\n",
       "      <td>0.521946</td>\n",
       "      <td>0.043091</td>\n",
       "      <td>0.532258</td>\n",
       "      <td>0.098973</td>\n",
       "      <td>0.524326</td>\n",
       "      <td>0.046262</td>\n",
       "      <td>0.53671</td>\n",
       "      <td>0.067276</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.049451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.508378</td>\n",
       "      <td>0.070734</td>\n",
       "      <td>0.50634</td>\n",
       "      <td>0.052042</td>\n",
       "      <td>0.516559</td>\n",
       "      <td>0.105582</td>\n",
       "      <td>0.508012</td>\n",
       "      <td>0.054449</td>\n",
       "      <td>0.515656</td>\n",
       "      <td>0.074825</td>\n",
       "      <td>0.555717</td>\n",
       "      <td>0.068504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       f1_score_mean f1_score_std precision_mean  \\\n",
       "MLP Neural Network          0.666651     0.004608            0.5   \n",
       "Logistic Regression         0.589446     0.067411       0.514962   \n",
       "Support Vector Machine      0.545904     0.069495       0.498868   \n",
       "Random Forest               0.524571     0.064123       0.521946   \n",
       "KNN                         0.508378     0.070734        0.50634   \n",
       "\n",
       "                       precision_std recall_mean recall_std accuracy_mean  \\\n",
       "MLP Neural Network          0.005184         1.0        0.0           0.5   \n",
       "Logistic Regression         0.041459    0.741075    0.22397      0.509783   \n",
       "Support Vector Machine      0.015023    0.635484   0.199922      0.496748   \n",
       "Random Forest               0.043091    0.532258   0.098973      0.524326   \n",
       "KNN                         0.052042    0.516559   0.105582      0.508012   \n",
       "\n",
       "                       accuracy_std auc_roc_mean auc_roc_std auc_pr_mean  \\\n",
       "MLP Neural Network         0.005184     0.497052    0.078692    0.533995   \n",
       "Logistic Regression          0.0376     0.526611    0.040915    0.535623   \n",
       "Support Vector Machine     0.017391     0.488078    0.060018    0.537086   \n",
       "Random Forest              0.046262      0.53671    0.067276       0.557   \n",
       "KNN                        0.054449     0.515656    0.074825    0.555717   \n",
       "\n",
       "                       auc_pr_std  \n",
       "MLP Neural Network       0.067457  \n",
       "Logistic Regression      0.045732  \n",
       "Support Vector Machine   0.049541  \n",
       "Random Forest            0.049451  \n",
       "KNN                      0.068504  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.loc[df_result.index.isin(BASIC_MODEL_NAMES), :].sort_values('f1_score_mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c3991845154295a8ea433e1da902e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='order_by', options=('f1_score_mean', 'f1_score_std', 'precision_me…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def order_models_by(order_by):\n",
    "    display(df_result.sort_values(by=order_by, ascending=False))\n",
    "    return\n",
    "\n",
    "interact(order_models_by, order_by=METRICS);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classificador Aleatório**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def random_classifier_results(y_true, chance_for_class1=0.5, trials=100):\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    for i in range(trials):\n",
    "        y_pred = np.random.choice([0, 1], size=len(y_true), p=[1.0-chance_for_class1, chance_for_class1])\n",
    "        accuracies.append(metrics.accuracy_score(y_true, y_pred))\n",
    "        precisions.append(metrics.precision_score(y_true, y_pred))\n",
    "        recalls.append(metrics.recall_score(y_true, y_pred))\n",
    "        f1s.append(metrics.f1_score(y_true, y_pred))\n",
    "    print(f\"RANDOM CLASSIFIER ({100*chance_for_class1:.0f}% chance for class 1)\")\n",
    "    print(f\"- Accuracy: {np.mean(accuracies):.4f} +/- {np.std(accuracies):.5f}\") \n",
    "    print(f\"- Precision: {np.mean(precisions):.4f} +/- {np.std(precisions):.5f}\")\n",
    "    print(f\"- Recall: {np.mean(recalls):.4f} +/- {np.std(recalls):.5f}\")\n",
    "    print(f\"- F1-Score: {np.mean(f1s):.4f} +/- {np.std(f1s):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM CLASSIFIER (50% chance for class 1)\n",
      "- Accuracy: 0.5009 +/- 0.02601\n",
      "- Precision: 0.5010 +/- 0.02687\n",
      "- Recall: 0.4971 +/- 0.03918\n",
      "- F1-Score: 0.4985 +/- 0.02973\n"
     ]
    }
   ],
   "source": [
    "random_classifier_results(dfy, 0.50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Melhores Hiper-Parâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Valores de parâmetros mais frequentes entre os melhores, por modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94d64b2e25547e0a31e2b1e0b3554f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='model_name', options=('MLP Neural Network', 'Support Vector Machin…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.aggregate_best_params(model_name)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def aggregate_best_params(model_name):\n",
    "    best_params_list = results[model_name]['best_parameters']\n",
    "    \n",
    "    # for each name of parameter, counts the number of times each of its value appeared among the best\n",
    "    params_count = dict()\n",
    "\n",
    "    for param_name in best_params_list[0].keys():\n",
    "        # fora each value of the parameter, counts the occurences\n",
    "        params_count[param_name] = Counter()\n",
    "        \n",
    "        for params in best_params_list:\n",
    "            if param_name == 'preproc':\n",
    "                param_value = params[param_name]._simplified_name\n",
    "            else:\n",
    "                param_value = params[param_name]\n",
    "            params_count[param_name][param_value] += 1\n",
    "    \n",
    "    display(params_count)\n",
    "\n",
    "#aggregate_best_params('Logistic Regression')\n",
    "interact(aggregate_best_params, model_name=BASIC_MODEL_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Melhor modelo *básico* por fold (e seus hiperparâmetros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0 - best model is a 'MLP Neural Network' with hiper parameters:\n",
      " - pca: PCA(n_components=10)\n",
      " - predictor__hidden_layer_sizes: (4,)\n",
      " - predictor__learning_rate_init: 0.001\n",
      " - scaler: MinMaxScaler()\n",
      " - F1 score: 0.6667\n",
      "FOLD 1 - best model is a 'MLP Neural Network' with hiper parameters:\n",
      " - pca: PCA(n_components=10)\n",
      " - predictor__hidden_layer_sizes: (4,)\n",
      " - predictor__learning_rate_init: 0.001\n",
      " - scaler: MinMaxScaler()\n",
      " - F1 score: 0.6667\n",
      "FOLD 2 - best model is a 'MLP Neural Network' with hiper parameters:\n",
      " - pca: PCA(n_components=10)\n",
      " - predictor__hidden_layer_sizes: (4,)\n",
      " - predictor__learning_rate_init: 0.001\n",
      " - scaler: MinMaxScaler()\n",
      " - F1 score: 0.6667\n",
      "FOLD 3 - best model is a 'MLP Neural Network' with hiper parameters:\n",
      " - pca: PCA(n_components=10)\n",
      " - predictor__hidden_layer_sizes: (4,)\n",
      " - predictor__learning_rate_init: 0.001\n",
      " - scaler: MinMaxScaler()\n",
      " - F1 score: 0.6593\n",
      "FOLD 4 - best model is a 'MLP Neural Network' with hiper parameters:\n",
      " - pca: PCA(n_components=10)\n",
      " - predictor__hidden_layer_sizes: (4,)\n",
      " - predictor__learning_rate_init: 0.001\n",
      " - scaler: MinMaxScaler()\n",
      " - F1 score: 0.6739\n",
      "FOLD 5 - best model is a 'MLP Neural Network' with hiper parameters:\n",
      " - pca: PCA(n_components=10)\n",
      " - predictor__hidden_layer_sizes: (4,)\n",
      " - predictor__learning_rate_init: 0.001\n",
      " - scaler: MinMaxScaler()\n",
      " - F1 score: 0.6667\n",
      "FOLD 6 - best model is a 'MLP Neural Network' with hiper parameters:\n",
      " - pca: PCA(n_components=10)\n",
      " - predictor__hidden_layer_sizes: (4,)\n",
      " - predictor__learning_rate_init: 0.001\n",
      " - scaler: MinMaxScaler()\n",
      " - F1 score: 0.6667\n",
      "FOLD 7 - best model is a 'MLP Neural Network' with hiper parameters:\n",
      " - pca: PCA(n_components=10)\n",
      " - predictor__hidden_layer_sizes: (4,)\n",
      " - predictor__learning_rate_init: 0.001\n",
      " - scaler: MinMaxScaler()\n",
      " - F1 score: 0.6667\n",
      "FOLD 8 - best model is a 'MLP Neural Network' with hiper parameters:\n",
      " - pca: PCA(n_components=10)\n",
      " - predictor__hidden_layer_sizes: (4,)\n",
      " - predictor__learning_rate_init: 0.001\n",
      " - scaler: MinMaxScaler()\n",
      " - F1 score: 0.6593\n",
      "FOLD 9 - best model is a 'Random Forest' with hiper parameters:\n",
      " - pca: PCA(n_components=20)\n",
      " - predictor__max_depth: None\n",
      " - predictor__min_samples_split: 8\n",
      " - predictor__n_estimators: 10\n",
      " - F1 score: 0.6761\n"
     ]
    }
   ],
   "source": [
    "def list_best_model_per_fold():\n",
    "    for fold in range(TOTAL_SPLITS):   \n",
    "        best_f1 = 0.0\n",
    "        best_model_params = None\n",
    "        best_model_name = None\n",
    "        for model_name in BASIC_MODEL_NAMES:\n",
    "            if results[model_name]['f1_score_list'][fold] > best_f1:\n",
    "                best_f1 = results[model_name]['f1_score_list'][fold]\n",
    "                best_model_params = results[model_name]['best_parameters'][fold]\n",
    "                best_model_name = model_name\n",
    "        \n",
    "        print(f\"FOLD {fold} - best model is a '{best_model_name}' with hiper parameters:\")\n",
    "        if best_model_params is not None:\n",
    "            for key in best_model_params:\n",
    "                if key is not None:\n",
    "                    print(f\" - {key}: {best_model_params[key]}\")\n",
    "        print(f\" - F1 score: {results[best_model_name]['f1_score_list'][fold]:.4f}\")\n",
    "\n",
    "list_best_model_per_fold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Melhores hiperparâmetros de cada modelo (em todos os folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observação: A seção 3.1 mostra esta informação de forma mais condensada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e3aea87bd84f12ade44cf169ebebdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='model_name', options=('MLP Neural Network', 'Support Vector Machin…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.list_all_best_params(model_name)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_all_best_params(model_name):\n",
    "    best_params_list = results[model_name]['best_parameters']\n",
    "    for i, paramset in enumerate(best_params_list):\n",
    "        print(\"BEST PARAM SET IN FOLD\", i, \":\")\n",
    "        for key in paramset.keys():\n",
    "            print(f\" - {key}: {paramset[key]}\")\n",
    "        print(f\" - F1 score: {results[model_name]['f1_score_list'][i]:.4f}\")\n",
    "\n",
    "\n",
    "#list_all_best_params('Logistic Regression')\n",
    "#list_all_best_params('Random Forest')\n",
    "#list_all_best_params('Support Vector Machine')\n",
    "\n",
    "interact(list_all_best_params, model_name=BASIC_MODEL_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Curvas ROC e PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from classification_train_util import plot_roc_curve, plot_pr_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff7a62ef7674a5fa9098719db73160f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='model_name', options=('MLP Neural Network', 'Support Vector Machin…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_model_roc_curves(model_name, overlapped=True)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_model_roc_curves(model_name, overlapped=True):\n",
    "    if overlapped:\n",
    "        # Plot ROC curves for all folds in a single plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for fold in range(TOTAL_SPLITS):\n",
    "            plot_roc_curve(results, model_name=model_name, fold=fold, show_plot=False, plot_ref_line=False)\n",
    "        plt.plot([0, 1], [0, 1], 'r--', label='Random Guess')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.title(f'Curva ROC - {model_name} (Overlapped)')\n",
    "    \n",
    "    else:\n",
    "        # Calculate the number of rows needed for two columns\n",
    "        n_rows = (TOTAL_SPLITS + 1) // 2\n",
    "\n",
    "        # Create a figure with subplots arranged in two columns\n",
    "        fig, axes = plt.subplots(n_rows, 2, figsize=(10, 4 * n_rows))  # Adjust width and height\n",
    "\n",
    "        # Flatten the axes array for easier indexing\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        # Plot each fold's ROC curve\n",
    "        for fold in range(TOTAL_SPLITS):\n",
    "            ax = axes[fold]\n",
    "            plt.sca(ax)  # Set current axis\n",
    "            plot_roc_curve(results, model_name=model_name, fold=fold, show_plot=False, plot_ref_line=True)\n",
    "            ax.set_title(f'Curva ROC - {model_name} (Fold {fold + 1})')\n",
    "\n",
    "        # Hide any unused subplots\n",
    "        for i in range(TOTAL_SPLITS, len(axes)):\n",
    "            axes[i].axis('off')\n",
    "\n",
    "    # Adjust layout for better spacing\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the combined plot\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_model_roc_curves, model_name=results.keys(), overlapped=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "509300c02105481887e6f4f190f8dc1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='model_name', options=('MLP Neural Network', 'Support Vector Machin…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_model_pr_curves(model_name, overlapped=True)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot_model_pr_curves(model_name, overlapped=True):\n",
    "    if overlapped:\n",
    "        # Plot ROC curves for all folds in a single plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for fold in range(TOTAL_SPLITS):\n",
    "            plot_pr_curve(results, model_name=model_name, fold=fold, show_plot=False)\n",
    "        plt.plot([0, 1], [0, 1], 'r--', label='Random Guess')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.title(f'Curva ROC - {model_name} (Overlapped)')\n",
    "    \n",
    "    else:\n",
    "        # Calculate the number of rows needed for two columns\n",
    "        n_rows = (TOTAL_SPLITS + 1) // 2\n",
    "\n",
    "        # Create a figure with subplots arranged in two columns\n",
    "        fig, axes = plt.subplots(n_rows, 2, figsize=(10, 4 * n_rows))  # Adjust width and height\n",
    "\n",
    "        # Flatten the axes array for easier indexing\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        # Plot each fold's ROC curve\n",
    "        for fold in range(TOTAL_SPLITS):\n",
    "            ax = axes[fold]\n",
    "            plt.sca(ax)  # Set current axis\n",
    "            plot_pr_curve(results, model_name=model_name, fold=fold, show_plot=False)\n",
    "            ax.set_title(f'Curva ROC - {model_name} (Fold {fold + 1})')\n",
    "\n",
    "        # Hide any unused subplots\n",
    "        for i in range(TOTAL_SPLITS, len(axes)):\n",
    "            axes[i].axis('off')\n",
    "\n",
    "    # Adjust layout for better spacing\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the combined plot\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_model_pr_curves, model_name=results.keys(), overlapped=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmujMeBpoAkU"
   },
   "source": [
    "# 5 - Importâncias dos Atributos(não sei se a gente vai estudar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UT5hVGjgAAwi"
   },
   "source": [
    "- Baseado nos valores de `feature_importances_` calculados em alguns modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1678973723605,
     "user": {
      "displayName": "PABLO SAMPAIO",
      "userId": "06578877141428254753"
     },
     "user_tz": 180
    },
    "id": "AfddNtwOrJyF",
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#@title Definições auxiliares (não precisa abrir)\n",
    "from sklearn.tree import plot_tree\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_importance(importances, title=None, max_features=None, feature_names=None, sort=True, ax=None):\n",
    "    \"\"\"\n",
    "    Plot feature importances for a scikit-learn random forest or gradient boosting model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : object\n",
    "        A scikit-learn random forest or gradient boosting model.\n",
    "    title: str or None, optional (default=None)\n",
    "        The title of the plot.\n",
    "    max_features : int or None, optional (default=None)\n",
    "        The maximum number of features to plot. If None, plot all features.\n",
    "    feature_names : list or None, optional (default=None)\n",
    "        A list of feature names to use in the plot. If None, use the feature indices.\n",
    "    sort : bool, optional (default=True)\n",
    "        Whether to sort the feature importances in descending order.\n",
    "    ax : matplotlib.axes.Axes or None, optional (default=None)\n",
    "        The matplotlib axes to plot the feature importances on. If None, create a new figure and axes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ax : matplotlib.axes.Axes\n",
    "        The matplotlib axes containing the plot.\n",
    "\n",
    "    \"\"\"\n",
    "    # Extract feature importances\n",
    "    #importances = model.feature_importances_\n",
    "\n",
    "    # Get feature names\n",
    "    if feature_names is None:\n",
    "        feature_names = [str(i) for i in range(len(importances))]\n",
    "\n",
    "    # Sort feature importances\n",
    "    if sort:\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        importances = importances[indices]\n",
    "        feature_names = [feature_names[i] for i in indices]\n",
    "\n",
    "    # Truncate feature importances\n",
    "    if max_features is not None:\n",
    "        importances = importances[:max_features]\n",
    "        feature_names = feature_names[:max_features]\n",
    "\n",
    "    # Create plot\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "   \n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=12)\n",
    "\n",
    "    ax.barh(np.arange(len(importances)), importances, align='center')\n",
    "    ax.set_yticks(np.arange(len(importances)))\n",
    "    ax.set_yticklabels(feature_names)\n",
    "    #ax.set_xlabel('Gini importance', fontsize=10)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "if 'Decision Tree' in results:\n",
    "    # best model of the 1st fold of the outer cross-validation\n",
    "    dec_tree_pipeline = results['Decision Tree']['melhores_modelos'][0]\n",
    "\n",
    "    # fit the pipeline to the WHOLE dataset\n",
    "    dec_tree_pipeline.fit(dfx, dfy)\n",
    "\n",
    "    display(dec_tree_pipeline)\n",
    "    \n",
    "    # the decision tree model inside the pipeline\n",
    "    dec_tree = dec_tree_pipeline.named_steps['predictor']\n",
    "    feature_names = dec_tree_pipeline.named_steps['preproc'].get_feature_names_out()\n",
    "\n",
    "    fig = plt.figure(figsize=(22,15))\n",
    "    plot_tree(dec_tree, feature_names=list(feature_names), filled=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_translate = {'cat__': '', 'remainder__': '', \n",
    "                    'DiasDecorridos': 'Elapsed Days', \n",
    "                    'Dispositivo Retórico': 'Rhetorical Device',\n",
    "                    'Retórica Aristotélica': 'Aristotelian Rhetoric',\n",
    "                    'Tipo de conteúdo': 'Content Type',\n",
    "                    'Texto': 'Text',\n",
    "                    'Tonalidade': 'Tone',\n",
    "                    'Duracao': 'Duration',\n",
    "                    'Abordagem': 'Approach'}\n",
    "\n",
    "def translate_feature_names(feature_names):\n",
    "    translated_names = []\n",
    "    for name in feature_names:\n",
    "        for k in to_translate.keys():\n",
    "            name = name.replace(k, to_translate[k])\n",
    "        translated_names.append(name)\n",
    "    return translated_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostras as importâncias para CADA um dos 5 modelos (dos 5 folds):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'melhores_modelos'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvote\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m model_name:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model_pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmelhores_modelos\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# the best model found in the first fold\u001b[39;00m\n\u001b[0;32m      6\u001b[0m model_predictor \u001b[38;5;241m=\u001b[39m model_pipeline\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictor\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# testa se o modelo guarda as importâncias das features\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'melhores_modelos'"
     ]
    }
   ],
   "source": [
    "for model_name in results.keys():\n",
    "    if 'vote' in model_name:\n",
    "        continue\n",
    "\n",
    "    model_pipeline = results[model_name]['melhores_modelos'][0]  # the best model found in the first fold\n",
    "    model_predictor = model_pipeline.named_steps['predictor']\n",
    "\n",
    "    # testa se o modelo guarda as importâncias das features\n",
    "    if not hasattr(model_predictor, 'feature_importances_'):\n",
    "        print(f\"O modelo {model_name} não registra as importâncias das features\")\n",
    "        continue\n",
    "\n",
    "    fig, axs = plt.subplots(5, 1, figsize=(20, 50))\n",
    "    \n",
    "    # Configurando a validação cruzada externa (igual à da função de treinamento)\n",
    "    #cv_outer = StratifiedKFold(n_splits=5, shuffle=True, random_state=metadata['random_state'])\n",
    "\n",
    "    fold = 0\n",
    "    for train_ix, test_ix in cv_outer.split(dfx, dfy):\n",
    "    #for fold in range(5):\n",
    "        X_train = dfx.iloc[train_ix]\n",
    "        y_train = dfy.iloc[train_ix]\n",
    "\n",
    "        model_pipeline = results[model_name]['melhores_modelos'][fold]\n",
    "        model_predictor = model_pipeline.named_steps['predictor']\n",
    "        \n",
    "        model_pipeline.fit(X_train, y_train)\n",
    "        #model_pipeline.fit(dfx, dfy) # PENSAR: refazer o cv_outer ?\n",
    "\n",
    "        features = model_pipeline.named_steps['preproc'].get_feature_names_out()\n",
    "        importances = model_predictor.feature_importances_\n",
    "        plot_importance(importances, \n",
    "                        title=f\"Importância das features no modelo {model_name} / fold {fold+1}\", \n",
    "                        feature_names=features, max_features=20, \n",
    "                        ax=axs[fold])\n",
    "        fold += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostras as importâncias médias dos modelos agrupadas pelos que usam features semelhantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "for model_name in results.keys():\n",
    "    if 'vote' in model_name:\n",
    "        continue\n",
    "\n",
    "    model_pipeline = results[model_name]['melhores_modelos'][0]  # the best model found in the first fold\n",
    "    model_predictor = model_pipeline.named_steps['predictor']\n",
    "\n",
    "    # testa se o modelo guarda as importâncias das features\n",
    "    if not hasattr(model_predictor, 'feature_importances_'):\n",
    "        print(f\"O modelo {model_name} não registra as importâncias das features\")\n",
    "        continue\n",
    "\n",
    "    map_num_features_to_importances = dict()\n",
    "    \n",
    "    # groups the models that uses similarly modified features\n",
    "    for fold in range(TOTAL_SPLITS):\n",
    "        model_pipeline = results[model_name]['melhores_modelos'][fold]\n",
    "        model_predictor = model_pipeline.named_steps['predictor']\n",
    "        \n",
    "        # não precisa, porque já foi treinado na célula anterior\n",
    "        #model_pipeline.fit(...)\n",
    "\n",
    "        features = model_pipeline.named_steps['preproc'].get_feature_names_out()\n",
    "\n",
    "        num_features = len(features)\n",
    "        #print(\"Fold\", fold, \":\", num_features)\n",
    "\n",
    "        importances = model_predictor.feature_importances_\n",
    "        assert len(importances) == num_features\n",
    "\n",
    "        if num_features not in map_num_features_to_importances:\n",
    "            map_num_features_to_importances[num_features] = []\n",
    "        \n",
    "        map_num_features_to_importances[num_features].append((features, importances))\n",
    "\n",
    "    # plot the importances for each group of models\n",
    "    num_groups = len(map_num_features_to_importances)\n",
    "    fig, axs = plt.subplots(num_groups, 1, figsize=(14, 5*num_groups))\n",
    "    \n",
    "    for subplot, num_features in enumerate(map_num_features_to_importances.keys()):\n",
    "        list_of_importances = map_num_features_to_importances[num_features]\n",
    "        num_models = len(list_of_importances)\n",
    "        \n",
    "        # just to assure that the feature names are the same\n",
    "        # across the different model configurations\n",
    "        for j in range(len(list_of_importances)-1):\n",
    "            assert (list_of_importances[j][0] == list_of_importances[j+1][0]).all()\n",
    "\n",
    "        features = list_of_importances[0][0]\n",
    "        features = translate_feature_names(features)\n",
    "        mean_importances = np.mean([imp for (_, imp) in list_of_importances], axis=1)\n",
    "        \n",
    "        if num_groups > 1:\n",
    "            param_ax = axs[subplot]\n",
    "        else:\n",
    "            param_ax = axs\n",
    "        \n",
    "        # ATENÇÃO: isso se aplica aos modelos com dados apenas de Lula ou apenas de Bolsonaro (o geral deve ter 43 features)\n",
    "        cat_feature_encoding = 'one-hot encoding' if len(features)==42 else 'target encoding'\n",
    "        letter_s_if_plural   = 's' if num_models > 1 else ''\n",
    "\n",
    "        plot_importance(importances, \n",
    "                        title=f\"Random Forest's average Gini importance ({num_models} configuration{letter_s_if_plural} with {cat_feature_encoding})\", \n",
    "                        feature_names=features, \n",
    "                        max_features=20, \n",
    "                        ax=param_ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIM"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOuiv0RFkkwcXnb26LS0lwg",
   "provenance": [
    {
     "file_id": "1y8SEBwz0ltHkmfXNFpsBTWvHkCb-CFdt",
     "timestamp": 1676506165799
    }
   ]
  },
  "kernelspec": {
   "display_name": "socialnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
