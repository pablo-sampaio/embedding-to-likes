{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Embeddings\n",
    "\n",
    "Ajuda a calcular embeddings dos dados adquiridos dos comentários das redes sociais de políticos. (Planilha de Gabrielly)\n",
    "\n",
    "Entrada: `LulaTotal Validado.xlsx` e `Bolsonaro Validado.xlsx`\n",
    "\n",
    "Saída: `Embeddings_(NOME_DO_MODELO)_(REDE_SOCIAL).xlsx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "BASE_PATH = 'dados/'\n",
    "DIRECTORY = BASE_PATH + 'preprocessed/embeddings/'\n",
    "SOCIAL_NETWORK = 'tiktok'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_types = {'ID' : str}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Leitura de Arquivos e inicialização de Variáveis\n",
    "\n",
    "Iniciação das variáveis que iremos utilizar e das colunas na qual iremos trabalhar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Pegar o modelo para testar\n",
    "TYPE_MODEL = 'BAAI/bge-m3'\n",
    "model = SentenceTransformer(TYPE_MODEL)\n",
    "\n",
    "# 2. Pegar as sentenças (nesse caso, no Post-filtrado)\n",
    "file_pathL = BASE_PATH + 'input/LulaTotal Validado.xlsx'\n",
    "file_pathB = BASE_PATH + 'input/Bolsonaro Validado.xlsx'\n",
    "file_path_features = 'Embeddings_bge-m3_'+ (SOCIAL_NETWORK) +'.xlsx'\n",
    "#é bom modificar o nome manualmente, pois pode dar erro na questão do save\n",
    "\n",
    "column_text = \"Texto\"\n",
    "column_id = \"ID\"\n",
    "column_author = \"Perfil\"\n",
    "column_likes = \"Curtidas\"\n",
    "column_inicial_date = \"DataColeta\"\n",
    "column_final_date = \"DataPost\"\n",
    "column_cand = \"Candidato\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converte para datetime \n",
    "def adjust_dates(df_aux):\n",
    "    df_aux['DataColeta'] = pd.to_datetime(df_aux['DataColeta'])\n",
    "    df_aux['DataPost'] = pd.to_datetime(df_aux['DataPost'])\n",
    "\n",
    "    try:\n",
    "        # converte esta coluna para conter uma string com o dia da semana\n",
    "        df_aux['DiaDaSemana'] = pd.to_datetime(df_aux['DiaDaSemana'])\n",
    "        df_aux['DiaDaSemana'] = df_aux['DiaDaSemana'].dt.strftime('%A')\n",
    "    except:\n",
    "        print(\"Coluna DiaDaSemana parece já estar guardado como date. Não precisa transformar!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Ler os Arquivos tanto de Lula quanto de bolsonaro\n",
    "df_lula = pd.read_excel(file_pathL, dtype=column_types)\n",
    "df_bolsonaro = pd.read_excel(file_pathB, dtype=column_types)\n",
    "\n",
    "df_lula.shape, df_bolsonaro.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "União das planilha e limpeza de variáveis que estão em branco, ou seja, não possuem utilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.concat([df_lula, df_bolsonaro], axis=0)\n",
    "df_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_total['ID'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = df_total.reset_index(drop=True)\n",
    "df_total.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observar o que foi eliminado e conferir se está tudo certo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total[df_total.isna().sum(axis=1) > 0].groupby('Perfil').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.loc[df_total.isna().sum(axis=1) > 0].shape\n",
    "df_total.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Configuração da planilha pré-processada\n",
    "## 2.1 Limpeza de colunas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop de colunas que não iremos utilizar como por exemplo `Duração` ou até `Dispositivo Retórico` etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.drop(columns=[\"Unnamed: 0\",\"Plays\",\"Comentarios\",\"Compart.\",\"Duracao\", \"LinkFoto\", \"LinkVideo\", \"LinkPost\", \n",
    "                       \"Retórica Aristotélica\", \"Dispositivo Retórico\", \"Tipo de conteúdo\",\n",
    "                  \"Abordagem\", \"Tonalidade\", \"Main character\", \"Texto / Hashtag\"], inplace=True)\n",
    "df_total.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.loc[df_total.isna().sum(axis=1) > 0].shape\n",
    "df_total.dropna(inplace=True)\n",
    "df_total.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversão de datas para calcular a coluna de `Dias Decorridos`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converte para datetime\n",
    "adjust_dates(df_total)\n",
    "df_total.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.groupby(['DataColeta']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['DiasDecorridos'] = (df_total['DataColeta'] - df_total['DataPost']).dt.days\n",
    "df_total\n",
    "\n",
    "df_total['Candidato'] = df_total['Perfil'].apply(lambda x: 'Lula' if x == 'lulaoficial' else 'Bolsonaro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Flag para análise de Hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para verificar se o texto contém apenas hashtags\n",
    "\n",
    "Caso o comentário só possua hashtags ele irá retornar  `true`, caso contrário a função retorna `false`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def contains_only_hashtags(text):\n",
    "    hashtags = re.findall(r'#\\S+', text)\n",
    "    return len(hashtags) == len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df_total[column_id].tolist()\n",
    "authors = df_total[column_author].tolist()\n",
    "sentences = df_total[column_text].tolist()\n",
    "likes = df_total[column_likes].tolist()\n",
    "days = df_total['DiasDecorridos'].tolist()\n",
    "candidatos = df_total['Candidato'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode dos embeddings utilizando a library do \"sentence-transformers\" e também a concatenação de dados previamente informados da planilha passada como `ID`,`Candidato` e `Curtidas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Calcular os embeddings das sentenças\n",
    "embeddings = model.encode(sentences)\n",
    "df_embeddings = pd.DataFrame(embeddings) \n",
    "df_embeddings.columns = [f'x{i+1}' for i in range(df_embeddings.shape[1])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embeddings.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A planilha ficará com as colunas importantes originais (__ID__,__Candidato__ e __Curtidas__), e também estará com uma flag que mostra se há hashtags(__Only Hashtags__), e por fim, features calculadas pelo embeddinG   __x1__,__x2__,__x3__ ... __xN__ , onde N seria o tamanho de dimensões que aquele modelo possui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Concatenar e Salvar o Arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.DataFrame({\n",
    "    column_id: ids,\n",
    "    'Candidato': candidatos,\n",
    "    column_likes: likes,\n",
    "    'Dias Decorridos': days\n",
    "    \n",
    "})\n",
    "\n",
    "df_final['Only Hashtags'] = df_total[column_text].apply(contains_only_hashtags)\n",
    "df_final['Only Hashtags'] = df_final['Only Hashtags'].fillna(False)  # Para lidar com tabulações que o pandas não reconhece\n",
    "\n",
    "# Concatena com df_embeddings\n",
    "df_final = pd.concat([df_final, df_embeddings], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.tail(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Salvar o arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_final.to_excel((DIRECTORY + file_path_features), index=False)\n",
    "\n",
    "print(\"Arquivo salvo:\", file_path_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
